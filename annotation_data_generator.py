#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jul 10 09:54:47 2018

@author: daniel

File to create a comprehensive data set drawing from the original microscope
images, annotations generated by the tierpsy tracker, and 
hand-drawn annotations
"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from copy import copy
import tables

from utility_functions import masks_from_XML


# define the various directories
DATA_DIR = '/Users/daniel/Documents/UCL/Project/Data/annotation-data'
VIDEOS_DIR = os.path.join(DATA_DIR, 'MaskedVideos')
FEATURES_DIR = os.path.join(DATA_DIR, 'Results')
ANNS_DIR = os.path.join(DATA_DIR, 'annotations_july')
#OUTPUT_DIR = os.path.join(DATA_DIR, 'collated_dataset')


# get list of file names
fNames = sorted([f for f in os.listdir(ANNS_DIR) if not f.startswith('.') if not f.endswith('212337')]) #exclude the worst annotation folder
print("Filenames: ")
print("\n".join(fNames))
print("")


# Loop through each of the datasets
for filename in fNames:

    # set which dataset we are using
    print("Set being created: {}".format(filename))
    
    # define the filenames for the images, features, and XML annotations
    images_file = os.path.join(VIDEOS_DIR, filename + ".hdf5")
    features_file = os.path.join(FEATURES_DIR, filename + "_featuresN.hdf5")
    XML_DIR = os.path.join(ANNS_DIR, filename)

    CROPPED_OUTPUT_DIR = os.path.join(DATA_DIR, 'cropped_collated_dataset', filename)
    

    # load images file
    with pd.HDFStore(features_file, 'r') as fid:
        #all the worm coordinates and how the skeletons matrix related with a given frame is here
        trajectories_data = fid['/trajectories_data'] 
        
    # Get total number of frames in file:
    num_frames = trajectories_data['frame_number'].max()
    
    # Load every 70th frame
    for frame_number in range(num_frames)[1::70]:
        print(frame_number)

        # read image (full or masked)
        img_field = '/mask'
#        img_field = "/full_data"

        # Select only the data for this frame
        traj_g = trajectories_data.groupby('frame_number')
        frame_data = traj_g.get_group(frame_number)
    
        # load existing annotations
        
        # Select only skeletonised worms
        # worms that where not succesfully skeletonized will have a -1 here
        skel_id = frame_data['skeleton_id'].values
        neg_skel_id = skel_id[skel_id<0]
        skel_id = skel_id[skel_id>=0]
        
        # Open the frame from the hdf5 file
        with tables.File(images_file, 'r') as fid:
            img = fid.get_node(img_field)[frame_number]
            img = img.T
        
        # get the worm contour coordinates
        with tables.File(features_file, 'r') as fid:
            # Reduce the coordinates by a factor of 10 so that they
            # match the image dimensions
            skel = fid.get_node('/coordinates/skeletons')[skel_id, :, :]/10
            cnt1 = fid.get_node('/coordinates/dorsal_contours')[skel_id, :, :]/10
            cnt2 = fid.get_node('/coordinates/ventral_contours')[skel_id, :, :]/10
        
#        # Plot the image with Tierpsy annotations
#        # Note we have to transpose the image to match the XML annotations
#        # Suspect this is due to MATLAB vs Numpy / col- vs row-major indexing
        
#        plt.figure(figsize=(30,30))
#        plt.imshow(img.T, interpolation='none', cmap='gray')
#        
#        #add all the worms identified
#        for _, row in frame_data.iterrows():
#           cc = plt.Circle((row['coord_y'], row['coord_x']), \
#                           row['roi_size']/2, lw=2, color='g', fill=False)
#           plt.gca().add_artist(cc)
#        
#        # add all the skeletonized worms
#        
#        # We also have to transpose the X and Y coordinates of the plots
#        for (ss, cc1, cc2) in zip(skel, cnt1, cnt2):
#            plt.plot(ss[:, 1], ss[:, 0], 'r')
#            plt.plot(cc1[:, 1], cc1[:, 0], 'tomato')
#            plt.plot(cc2[:, 1], cc2[:, 0], color='salmon')
#            
#        plt.show()
#        plt.close()

        # Get annotations as complete masks, starting with existing data
        masks = []
        
        # Loop through all of the existing worms 
        for (cc1, cc2) in zip(cnt1, cnt2):
            cnt_close = np.vstack([cc1, cc2[-1::-1]])
            
            # convert the outline to a solid mask
            mask = np.zeros(img.shape)
            cv2.fillPoly(mask, pts =[np.int32(cnt_close)], color=(255,255,255))
            
            #append this mask to our list of masks
            # note we have to transpose this mask
            masks.append(copy(mask.T))
            
                
        # load xml annotations (if they exist for this frame)
        # and append them to the list of masks
        annotation_path = os.path.join(XML_DIR, str(frame_number) + ".xml")
        if os.path.exists(annotation_path):
            xml_masks, xml_heads = masks_from_XML(annotation_path, img)
            masks.extend(copy(xml_masks))
            
            
        h = img.shape[0]
        w = img.shape[1]
        
        # Splitting the images into 16 smaller chunks
        # Originially the images are 2048*2048 however this is far too large
        # to fit in to GPU RAM. 
        for x in range(4):
            for y in range(4):
                
                # We loop through all the chunks and set pos_example = True if
                # the chunk contains at least part of a worm, keeping only
                # those chunks.
                pos_example = False
        
        
                j = 0
                
                # Loop through all of the worms 
                for m in masks: 
                    # crop the mask for the chunk being examined
                    cropped_mask = m[int((h/4)*x):int((h/4)*(x+1)), int((w/4)*y):int((w/4)*(y+1))]
        
                    # if the chunk contains a worm:
                    if np.any(cropped_mask):
                        # Create a subdir for the masks for this crop
                        os.makedirs(CROPPED_OUTPUT_DIR + '/{}_{}{}/masks'.format(frame_number,x,y), exist_ok=True)
                        mask_filename = CROPPED_OUTPUT_DIR + '/{}_{}{}/masks/mask_{}.png'.format(frame_number,x,y,j)
                        plt.imsave(fname=mask_filename, arr=cropped_mask, format='png', cmap='gray')
                        
                        # Set this flag True to save this image crop
                        pos_example = True
        
                    j += 1
        
                if pos_example:
                     os.makedirs(CROPPED_OUTPUT_DIR + '/{}_{}{}/image'.format(frame_number,x,y), exist_ok=True)
                     cropped_img = img[int((h/4)*x):int((h/4)*(x+1)), int((w/4)*y):int((w/4)*(y+1))]
                     image_filename = CROPPED_OUTPUT_DIR + '/{}_{}{}/image/image_{}_{}{}.png'.format(frame_number,x,y,frame_number,x,y)
                     plt.imsave(fname=image_filename, arr=cropped_img, format='png', cmap='gray')
        

        
#TODO: make this script output tf.record files (sharded by set?)
        
        
        
