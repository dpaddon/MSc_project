{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask RCNN inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:36.068034Z",
     "start_time": "2018-09-01T15:43:30.891503Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "# sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "from copy import copy\n",
    "import cv2\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.models.research.object_detection.utils import label_map_util\n",
    "from tensorflow.models.research.object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "from utility_functions import load_image_into_numpy_array\n",
    "from utility_functions import run_inference_for_single_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:36.078961Z",
     "start_time": "2018-09-01T15:43:36.073036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to frozen detection graph.\n",
    "MODEL_NAME = 'inception_v2/fine_tuned_model_100k_final_sets'\n",
    "PATH_TO_CKPT = os.path.join('./downloaded_models', MODEL_NAME, 'frozen_inference_graph.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:37.081510Z",
     "start_time": "2018-09-01T15:43:36.081772Z"
    }
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:37.103017Z",
     "start_time": "2018-09-01T15:43:37.086634Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = '/Users/daniel/Documents/UCL/Project/Code/tensorflow_Mask_RCNN/data/worm_label_map.pbtxt'\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:37.122829Z",
     "start_time": "2018-09-01T15:43:37.109799Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_IMAGES = 5\n",
    "\n",
    "DATASET_DIR = './data/fullsize_images/'\n",
    "datasets = [f for f in os.listdir(DATASET_DIR) if not f.startswith('.')]\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:37.149145Z",
     "start_time": "2018-09-01T15:43:37.126674Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets[4]\n",
    "print(\"Running inference on dataset {}\".format(dataset))\n",
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = os.path.join(DATASET_DIR, dataset)\n",
    "# PATH_TO_TEST_IMAGES_DIR = '/Users/daniel/Documents/UCL/Project/Data/annotation-data/fullsize_collated_dataset/NIC199_worms10_food1-10_Set7_Pos4_Ch4_19052017_153012/'\n",
    "\n",
    "\n",
    "FNAMES = [f for f in os.listdir(PATH_TO_TEST_IMAGES_DIR) if not f.startswith('.')]\n",
    "FNAMES = sorted(FNAMES, key=int)[:NUM_IMAGES]\n",
    "# TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}/image/image_{}.png'.format(i,i)) for i in FNAMES] # np.random.choice(len(FNAMES), size=NUM_IMAGES, replace=False)]\n",
    "\n",
    "# Size of output images.\n",
    "IMAGE_SIZE = (40,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:46:08.435639Z",
     "start_time": "2018-09-01T15:44:07.953037Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dicts_list = []\n",
    "inference_times = []\n",
    "\n",
    "visualise_outputs = True\n",
    "save_anns_to_file = False\n",
    "save_overlays_to_file = False\n",
    "\n",
    "\n",
    "for fName in FNAMES:\n",
    "    \n",
    "    image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}/image/image_{}.png'.format(fName,fName))\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    \n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "    print(\"Inference for one image: {}.{}s\".format(elapsed.seconds,round(elapsed.microseconds,2))) \n",
    "    inference_times.append(elapsed.seconds)\n",
    "\n",
    "    if visualise_outputs:\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          output_dict['detection_boxes'],\n",
    "          output_dict['detection_classes'],\n",
    "          output_dict['detection_scores'],\n",
    "          category_index,\n",
    "          instance_masks=output_dict.get('detection_masks'),\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=2)\n",
    "        plt.figure(figsize=IMAGE_SIZE)\n",
    "        plt.title(\"Image {}\".format(image_path[:-4]))\n",
    "        plt.imshow(image_np)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # Keeping only worms which scored > 0.5\n",
    "    found_worms = np.where(output_dict['detection_scores'] > 0.5)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][found_worms]\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'][found_worms]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][found_worms]\n",
    "    output_dict['detection_masks'] = output_dict['detection_masks'][found_worms]\n",
    "    output_dict['skeletons'] = []\n",
    "    output_dict['frame_num'] = fName\n",
    "    \n",
    "    for m in output_dict['detection_masks']:\n",
    "        output_dict['skeletons'].append(skeletonize(m).astype(np.uint8))\n",
    "\n",
    "    \n",
    "    OUTPUT_DIR_PATH = os.path.join('./data/inference_outputs', MODEL_NAME, dataset)\n",
    "\n",
    "    \n",
    "    if save_anns_to_file:\n",
    "        #Save outputs to Pickle file\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'annotations'), exist_ok=True)\n",
    "        ANNS_OUTPUT_PATH = os.path.join(OUTPUT_DIR_PATH,'annotations', fName) + '.pickle'\n",
    "        with open(ANNS_OUTPUT_PATH, 'wb') as fp:\n",
    "            pickle.dump(output_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    if save_overlays_to_file:\n",
    "        #save image with annotations overlaid to file\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n",
    "        IMG_OUTPUT_PATH = os.path.join(OUTPUT_DIR_PATH,'images', fName) + '.png'\n",
    "        \n",
    "        plt.figure(figsize=IMAGE_SIZE)\n",
    "        \n",
    "        # If the image ahsn't already been visualised, we need \n",
    "        # to add the masks and boxes now\n",
    "        if not visualise_outputs:\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              output_dict['detection_boxes'],\n",
    "              output_dict['detection_classes'],\n",
    "              output_dict['detection_scores'],\n",
    "              category_index,\n",
    "              instance_masks=output_dict.get('detection_masks'),\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=1)\n",
    "            \n",
    "        plt.imshow(image_np)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(fname=IMG_OUTPUT_PATH, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close\n",
    "        \n",
    "    \n",
    "    output_dicts_list.append(output_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:57.535635Z",
     "start_time": "2018-09-01T15:43:30.898Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_time = round(sum(inference_times) / len(inference_times), 2)\n",
    "print(\"Average inference time for {} images: {}s\".format(NUM_IMAGES, mean_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skeletonisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the last image and its skeletons as a sense-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:57.536814Z",
     "start_time": "2018-09-01T15:43:30.900Z"
    }
   },
   "outputs": [],
   "source": [
    "skeletons = np.array(output_dicts_list[-1]['skeletons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:57.538217Z",
     "start_time": "2018-09-01T15:43:30.901Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,80))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image_np)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.sum(skeletons, axis=0))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking using SORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:57.539375Z",
     "start_time": "2018-09-01T15:43:30.903Z"
    }
   },
   "outputs": [],
   "source": [
    "from sort import sort\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:43:57.540644Z",
     "start_time": "2018-09-01T15:43:30.904Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display = True\n",
    "verbose = False\n",
    "colours = np.random.rand(32,3)\n",
    "\n",
    "\n",
    "\n",
    "#create instance of SORT\n",
    "worm_tracker = sort.Sort(max_age=5, min_hits=0) \n",
    "\n",
    "# get detections\n",
    "all_detections = [np.hstack((i['detection_boxes']*2048, np.expand_dims(i['detection_scores'],1))) for i in output_dicts_list]\n",
    "\n",
    "\n",
    "for frame in range(len(all_detections)):\n",
    "        \n",
    "    \n",
    "    # update SORT\n",
    "    detections = all_detections[frame]\n",
    "\n",
    "    \n",
    "    ids = worm_tracker.update(detections)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Detections: {}'.format(detections))\n",
    "        print('ids shape: {}'.format(ids.shape))\n",
    "        print('ids: {}'.format(ids))\n",
    "    \n",
    "    print(\"Worm IDs: {}\".format(sorted(ids[:,-1], key=int)))\n",
    "    \n",
    "    if(display):\n",
    "        \n",
    "        fName = FNAMES[frame]\n",
    "    \n",
    "        image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}/image/image_{}.png'.format(fName,fName))\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        img_np = load_image_into_numpy_array(img)\n",
    "        \n",
    "        fig = plt.figure(figsize=(IMAGE_SIZE))\n",
    "        \n",
    "        \n",
    "        ax = fig.add_subplot(121, aspect='equal')\n",
    "        ax.imshow(img_np)\n",
    "\n",
    "        for d in ids:\n",
    "            d = d.astype(np.int32)\n",
    "            ax.add_patch(patches.Rectangle((d[1],d[0]),d[3]-d[1],d[2]-d[0],\n",
    "                                           fill=False,\n",
    "                                           lw=3,\n",
    "                                           ec=colours[d[4]%32,:]))\n",
    "            ax.set_adjustable('box-forced')\n",
    "            plt.text(d[1],d[0],d[-1],color='w')\n",
    "        \n",
    "        ax_2 = fig.add_subplot(122, aspect='equal')\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              img_np,\n",
    "              output_dicts_list[frame]['detection_boxes'],\n",
    "              output_dicts_list[frame]['detection_classes'],\n",
    "              output_dicts_list[frame]['detection_scores'],\n",
    "              category_index,\n",
    "              instance_masks=output_dicts_list[frame].get('detection_masks'),\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=2)\n",
    "        ax_2.imshow(img_np)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:47:06.256080Z",
     "start_time": "2018-08-10T13:47:06.245922Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
